# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021, xinetzone
# This file is distributed under the same license as the Apollo 文档 package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Apollo 文档 \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-11-23 19:11+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../../docs/specs/perception_apollo_5.0.md:1
msgid "Perception"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:2
msgid "Apollo 5.0 June 27, 2019"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:5
msgid "Introduction"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:7
msgid ""
"Apollo 5.0 Perception module introduced a few major features to provide "
"diverse functionality, a more reliable platform and a more robust "
"solution to enhance your AV performance. These include:"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:9
msgid ""
"**Supports Caffe and PaddlePaddle**: "
"[PaddlePaddle](https://github.com/PaddlePaddle/Paddle) (PArallel "
"Distributed Deep LEarning) is an easy-to-use, efficient, flexible and "
"scalable deep learning platform, which was originally developed by Baidu "
"scientists and engineers for the purpose of applying deep learning to "
"many products at Baidu."
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:10
msgid "**Online sensor calibration service**"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:11
msgid "**Manual camera calibration**"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:12
msgid "**Closest In-Path Object (CIPO) Detection**"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:13
msgid "**Vanishing Point Detection**"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:15
msgid "***Safety alert***"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:17
msgid ""
"Apollo 5.0 *does not* support a high curvature road, roads without lane "
"lines including local roads and intersections. The perception module is "
"based on visual detection using a deep network with limited data. "
"Therefore, before we release a better network, the driver should be "
"careful while driving and always be ready to disengage the autonomous "
"driving mode by intervening (hit the brakes or turn the steering wheel). "
"While testing Apollo 3.0, please choose a path that has the necessary "
"conditions mentioned above and be vigilant."
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:19
msgid "Perception module"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:20
msgid "The flow chart of Apollo 5.0 Perception module:"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:22
msgid "![Image](images/Apollo3.5_perception_detail.png)"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:22
msgid "Image"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:24
msgid ""
"To learn more about individual sub-modules, please visit [Perception - "
"Apollo 3.0](perception_apollo_3.0.md)"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:26
msgid "Supports PaddlePaddle"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:28
msgid ""
"The Apollo platform's perception module actively depended on Caffe for "
"its modelling, but will now support PaddlePaddle, an open source platform"
" developed by Baidu to support its various deep learning projects. Some "
"features include:"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:30
msgid ""
"**PCNNSeg**: Object detection from 128-channel lidar or a fusion of three"
" 16-channel lidars using PaddlePaddle"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:31
msgid "**PCameraDetector**: Object detection from a camera"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:32
msgid "**PlaneDetector**: Lane line detection from a camera"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:34
msgid "Using PaddlePaddle Features"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:36
msgid ""
"To use the PaddlePaddle model for Camera Obstacle Detector, set "
"`camera_obstacle_perception_conf_file` to `obstacle_paddle.pt` in the "
"following [configuration "
"file](https://github.com/ApolloAuto/apollo/blob/master/modules/perception/production/conf/perception/camera/fusion_camera_detection_component.pb.txt)"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:38
msgid ""
"To use the PaddlePaddle model for LiDAR Obstacle Detector, set "
"`use_paddle` to `true` in the following [configuration "
"file](https://github.com/ApolloAuto/apollo/blob/master/modules/perception/production/data/perception/lidar/models/cnnseg/velodyne128/cnnseg.conf)"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:40
msgid "Online sensor calibration service"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:42
msgid ""
"Apollo currently offers a robust calibration service to support your "
"calibration requirements from LiDARs to IMU to Cameras. This service is "
"currently being offered to select partners only. If you would like to "
"learn more about the calibration service, please reach out to us via "
"email: **apollopartner@baidu.com**"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:44
msgid "Manual Camera Calibration"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:46
msgid ""
"In Apollo 5.0, Perception launched a manual camera calibration tool for "
"camera extrinsic parameters. This tool is simple, reliable and user-"
"friendly. It comes equipped with a visualizer and the calibration can be "
"performed using your keyboard. It helps to estimate the camera's "
"orientation (pitch, yaw, roll). It provides a vanishing point, horizon, "
"and top down view as guidelines. Users would need to change the 3 angles "
"to align a horizon and make the lane lines parallel."
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:48
msgid "The process of manual calibration can be seen below:"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:50
msgid "![](images/Manual_calib.png)"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:52
msgid "Closest In-Path Object (CIPO) Detection"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:54
msgid ""
"The CIPO includes detection of key objects on the road for longitudinal "
"control. It utilizes the object and ego-lane line detection output. It "
"creates a virtual ego lane line using the vehicle's ego motion "
"prediction. Any vehicle model including Sphere model, Bicycle model and "
"4-wheel tire model can be used for the ego motion prediction. Based on "
"the vehicle model using the translation of velocity and angular velocity,"
" the length and curvature of the pseudo lanes are determined. Some "
"examples of CIPO using Pseudo lane lines can be seen below:"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:57
msgid "CIPO used for curved roads ![](images/CIPO_1.png)"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:60
msgid "CIPO for a street with no lane lines ![](images/CIPO_2.png)"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:64
msgid "Vanishing Point Detection"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:66
msgid ""
"In Apollo 5.0, an additional branch of network is attached to the end of "
"the lane encoder to detect the vanishing point. This branch is composed "
"of convolutional layers and fully connected layers, where convolutional "
"layers translate lane features for the vanishing point task and fully "
"connected layers make a global summary of the whole image to output the "
"vanishing point location. Instead of giving an output in `x`, `y` "
"coordinate directly, the output of vanishing point is in the form of "
"`dx`, `dy` which indicate its distances to the image center in `x`, `y` "
"coordinates. The new branch of network is trained separately by using "
"pre-trained lane features directly, where the model weights with respect "
"to the lane line network is fixed. The Flow Diagram is included below, "
"note that the red color denotes the flow of the vanishing point detection"
" algorithm."
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:68
msgid "![](images/Vpt.png)"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:70
msgid ""
"Two challenging visual examples of our vanishing point detection with "
"lane network output are shown below:"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:71
msgid ""
"Illustrates the case that vanishing point can be detected when there is "
"obstacle blocking the view:"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:73
msgid "![](images/Vpt1.png)"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:76
msgid "Illustrates the case of turning road with altitude changes:"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:78
msgid "![](images/Vpt2.png)"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:81
msgid "Key Features"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:83
msgid "Regression to `(dx, dy)` rather than `(x, y)` reduces the search space"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:84
msgid ""
"Additional convolution layer is needed for feature translation which "
"casts CNN features for vanishing point purpose"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:85
msgid ""
"Fully Connected layer is applied for holistic spatial summary of "
"information, which is required for vanishing point estimation"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:86
msgid ""
"The branch design supports diverse training strategies, e.g. fine tune "
"pre-trained laneline model, only train the subnet with direct use of "
"laneline features, co-train of multi-task network"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:88
msgid "Output of Perception"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:89
msgid ""
"The input of Planning and Control modules will be quite different with "
"that of the previous Lidar-based system for Apollo 3.0."
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:91
msgid "Lane line output"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:92
msgid "Polyline and/or a polynomial curve"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:93
msgid ""
"Lane type by position: L1(next left lane line), L0(left lane line), "
"R0(right lane line), R1(next right lane line)"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:95
msgid "Object output"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:96
msgid "3D rectangular cuboid"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:97
msgid "Relative velocity and direction"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:98
msgid "Type: CIPV, PIHP, others"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:99
msgid "Classification type: car, truck, bike, pedestrian"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:100
msgid "Drops: trajectory of an object"
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:102
msgid ""
"The world coordinate system is used as ego-coordinate in 3D where the "
"rear center axle is an origin."
msgstr ""

#: ../../docs/specs/perception_apollo_5.0.md:104
msgid ""
"If you want to try our perception modules and their associated "
"visualizer, please refer to the [following "
"document](https://github.com/ApolloAuto/apollo/blob/master/docs/howto/how_to_run_perception_module_on_your_local_computer.md)"
msgstr ""

