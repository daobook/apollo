# SOME DESCRIPTIVE TITLE.
# Copyright (C)
# This file is distributed under the same license as the Apollo Auto
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Apollo Auto \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-11-26 16:55+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../../../modules/perception/lidar/README.md:1
msgid "Lidar Perception"
msgstr ""

#: ../../../modules/perception/lidar/README.md:3
msgid "Introduction"
msgstr ""

#: ../../../modules/perception/lidar/README.md:4
msgid ""
"In Apollo 7.0, a new LiDAR-based obstacle detection model is provided "
"named Mask-Pillars based on PointPillars, which improves the original "
"version in two aspects. The first one is that a residual attention module"
" is introduced into the encoder of the backbone to learn a mask and to "
"enhance the feature map in a residual way. The second one is that a "
"pillar-level supervision is applied after decoder of the backbone which "
"is only performed in the training stage. The training data for pillar-"
"level supervision is generated by composing the distribution of "
"foreground obstacle pillars. From the experimental validation, Mask-"
"Pillars achieves higher performance than PointPillars on both Kitti and "
"Waymo datasets, especially the recall on obstacles."
msgstr ""

#: ../../../modules/perception/lidar/README.md:6
msgid "Architecture"
msgstr ""

#: ../../../modules/perception/lidar/README.md:7
msgid "Here we mainly focus on the modifications based on PointPillars:"
msgstr ""

#: ../../../modules/perception/lidar/README.md:8
msgid "Attention Module"
msgstr ""

#: ../../../modules/perception/lidar/README.md:9
msgid ""
"Although LiDAR can collect high-quality point cloud data, some obstacles "
"may have a small number of point clouds due to occlusion or distance. "
"Therefore, we introduce an attention layer on FPN encoder module to "
"enhance the features refer to [Residual Attention Network for Image "
"Classification](https://arxiv.org/abs/1704.06904). Since FPN has three "
"feature maps with different resolutions, our attention module also acts "
"on three feature maps at the same time. More details about the network "
"architecture can refer to figure below，S represent Sigmoid，F function is "
"shown as Formula 1："
msgstr ""

#: ../../../modules/perception/lidar/README.md:11
msgid ""
"\n"
"F(x) = (1 + M(x)) * T(x)\n"
"\\tag{1}\n"
msgstr ""

#: ../../../modules/perception/lidar/README.md:15
msgid "$T(x)$is the output of backbone，$M(x)$is the output of attention module."
msgstr ""

#: ../../../modules/perception/lidar/README.md:17
msgid "Pillar-level supervision"
msgstr ""

#: ../../../modules/perception/lidar/README.md:18
msgid ""
"In order to improve the recall of the network, we introduce a pillar-"
"level supervision mechanism in the training stage. We notice that the "
"segmentation algorithms always have high recall rates because of the "
"pixel level supervision. Therefore, we borrow the idea of segmentation "
"network by adding a pillar-level supervision of foreground pillars that "
"representing obstacles. The feature maps before feeding into the "
"detection module are supervised by the pillar supervision data, which are"
" represented as obstacle distributions. The supervision data are simply "
"generated by composing the Guassion distributions of obstacle pillars of "
"the training point cloud."
msgstr ""

#: ../../../modules/perception/lidar/README.md:20
msgid "The network structure of the final FPN is shown in the figure below"
msgstr ""

#: ../../../modules/perception/lidar/README.md:25
msgid "Results"
msgstr ""

#: ../../../modules/perception/lidar/README.md:26
msgid ""
"We apply the MMDetection3D framework for training. On the KITTI "
"validation set, the results are as shown in the below table. The results "
"of PointPillars comes from [mmdetction3d](https://github.com/open-"
"mmlab/mmdetection3d/blob/master/configs/pointpillars/README.md)"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "Method"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "3DmAP <br> Mod."
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "Car <br> Easy Mod. Hard"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "Pedestrian <br> Easy Mod. Hard"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "Cyclist <br> Easy Mod. Hard"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "PointPillars"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "60.11"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "85.41     73.98\t 67.76"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "52.02\t      46.40        42.48"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "78.72\t   59.95\t57.25"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "Ours"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "62.07"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "86.13     76.74\t 74.14"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "50.79\t      45.59\t       41.50"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "83.91\t   63.87\t61.05"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "BEVmAP <br> Mod."
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "67.76"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "89.93     86.57\t 85.20"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "59.08\t      53.36\t       48.42"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "80.93\t   63.34\t60.06"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "69.49"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "89.85     87.15\t 85.55"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "58.29\t      53.87\t       49.98"
msgstr ""

#: ../../../modules/perception/lidar/README.md
msgid "85.13\t   67.43\t63.85"
msgstr ""

#: ../../../modules/perception/lidar/README.md:44
msgid ""
"The detection visualization on KITTI data of PointPillars and our model "
"are shown as below. It can be seen that our model has better detection "
"performance. We can see that truncated and occluded vehicles are recalled"
" by our model."
msgstr ""

#: ../../../modules/perception/lidar/README.md:50
msgid "Online"
msgstr ""

#: ../../../modules/perception/lidar/README.md:51
msgid ""
"Here, we use libtorch for online deployment and use the torch.jit.trace "
"function of pytorch. We divide the original model into five parts. For "
"more details, please refer to the code："
msgstr ""

#: ../../../modules/perception/lidar/README.md:56
msgid "Launch"
msgstr ""

#: ../../../modules/perception/lidar/README.md:57
msgid ""
"In order to facilitate the extension of Apollo models, we refactor the "
"detection module that allows more pluggable detection models. To choose a"
" specific model, you only need to modify corresponding configuration "
"files. The configuration files are referred to:"
msgstr ""

#: ../../../modules/perception/lidar/README.md:61
msgid ""
"There are several directories in the path, which are related to "
"corresponding sensors. For LiDAR sensor, you could modify the value of "
"key \"detector\" in \"lidar_obstacle_detection.conf\" file to switch the "
"LiDAR-based detection model."
msgstr ""

#: ../../../modules/perception/lidar/README.md:63
msgid "Reference"
msgstr ""

#: ../../../modules/perception/lidar/README.md:64
msgid ""
"MMDetection3D: OpenMMLab next-generation platform for general 3D object "
"detection https://github.com/open-mmlab/mmdetection3d"
msgstr ""

