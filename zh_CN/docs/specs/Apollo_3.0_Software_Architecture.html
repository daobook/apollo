<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Apollo 3.0 Software Architecture &mdash; Apollo Auto alpha 文档</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/cyber/doxy-docs/source/main_stylesheet.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/tabs.js"></script>
        <script src="../../_static/translations.js"></script>
        <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
        <script>mermaid.initialize({startOnLoad:true});</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="Apollo 3.0 软件架构" href="Apollo_3.0_Software_Architecture_cn.html" />
    <link rel="prev" title="Apollo 2.0 Software Architecture" href="Apollo_2.0_Software_Architecture.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: skyblue" >
            <a href="../../index.html" class="icon icon-home"> Apollo Auto
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../README.html">Apollo Auto 自述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../README.html">Apollo Auto 文档</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cyber/doxy-docs/source/index.html">cyber 文档</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: skyblue" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Apollo Auto</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Apollo 3.0 Software Architecture</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/docs/specs/Apollo_3.0_Software_Architecture.md.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="apollo-3-0-software-architecture">
<h1>Apollo 3.0 Software Architecture<a class="headerlink" href="#apollo-3-0-software-architecture" title="永久链接至标题"></a></h1>
<p>Core software modules running on the Apollo 3.0 powered autonomous vehicle include:</p>
<ul class="simple">
<li><p><strong>Perception</strong> — The perception module identifies the world surrounding the autonomous vehicle. There are two important submodules inside perception: obstacle detection and traffic light detection.</p></li>
<li><p><strong>Prediction</strong> — The prediction module anticipates the future motion trajectories of the perceived obstacles.</p></li>
<li><p><strong>Routing</strong> — The routing module tells the autonomous vehicle how to reach its destination via a series of lanes or roads.</p></li>
<li><p><strong>Planning</strong> — The planning module plans the spatio-temporal trajectory for the autonomous vehicle to take.</p></li>
<li><p><strong>Control</strong> — The control module executes the planned spatio-temporal trajectory by generating control commands such as throttle, brake, and steering.</p></li>
<li><p><strong>CanBus</strong> — The CanBus is the interface that passes control commands to the vehicle hardware. It also passes chassis information to the software system.</p></li>
<li><p><strong>HD-Map</strong> — This module is similar to a library. Instead of publishing and subscribing messages, it frequently functions as query engine support to provide ad-hoc structured information regarding the roads.</p></li>
<li><p><strong>Localization</strong> — The localization module leverages various information sources such as GPS, LiDAR and IMU to estimate where the autonomous vehicle is located.</p></li>
<li><p><strong>HMI</strong> - Human Machine Interface or DreamView in Apollo is a module for viewing the status of the vehicle, testing other modules and controlling the functioning of the vehicle in real-time.</p></li>
<li><p><strong>Monitor</strong> - The surveillance system of all the modules in the vehicle including hardware.</p></li>
<li><p><strong>Guardian</strong> - A new safety module that performs the function of an Action Center and intervenes should Monitor detect a failure.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Note</span><span class="p">:</span> <span class="n">Detailed</span> <span class="n">information</span> <span class="n">on</span> <span class="n">each</span> <span class="n">of</span> <span class="n">these</span> <span class="n">modules</span> <span class="ow">is</span> <span class="n">included</span> <span class="n">below</span><span class="o">.</span>
</pre></div>
</div>
<p>The interactions of these modules are illustrated in the picture below.</p>
<p><img alt="img" src="../../_images/Apollo_3.0_SW.png" /></p>
<p>Every module is running as a separate CarOS-based ROS node. Each module node publishes and subscribes certain topics. The subscribed topics serve as data input while the published topics serve as data output. The detailed interactions are described in the following sections.</p>
<section id="perception">
<h2>Perception<a class="headerlink" href="#perception" title="永久链接至标题"></a></h2>
<p>Perception depends on the raw sensor data such as LiDAR point cloud data and camera data. In addition to these raw sensor data inputs, traffic light detection also depends on the localization data as well as the HD-Map. Because real-time ad-hoc traffic light detection is computationally infeasible,  traffic light detection needs localization to determine when and where to start detecting traffic lights through the camera captured pictures.
Changes to Apollo 3.0:</p>
<ul class="simple">
<li><p>CIPV detection/ Tailgating – moving within a single lane</p></li>
<li><p>Whole lane line support - bold line support for long range accuracy. There are 2 different types on installations for Camera, low and high installation.</p></li>
<li><p>Asynchronous sensor fusion – get all the information and get data points by asynchronously fusing LiDAR, Radar and Camera data. This is specifically important because of the frame rate differences in the different sensors – Radar is 10ms, Camera is 33ms and LiDAR is 100ms</p></li>
<li><p>Online pose estimation – determines angle change and estimates it when there are bumps or slopes to ensure that the sensors move with the car and the angle/pose changes accordingly</p></li>
<li><p>Visual localization – we now use camera for localization. This functionality is currently being tested.</p></li>
<li><p>Ultrasonic Sensor – Currently being tested as the final gatekeeper to be used in conjunction with Guardian for Automated Emergency brake and vertical/perpendicular parking.</p></li>
</ul>
</section>
<section id="prediction">
<h2>Prediction<a class="headerlink" href="#prediction" title="永久链接至标题"></a></h2>
<p>The prediction module estimates the future motion trajectories for all the perceived obstacles. The output prediction message wraps the perception information. Prediction subscribes to both localization and perception obstacle messages as shown below.</p>
<p><img alt="img" src="https://github.com/ApolloAuto/apollo/blob/master/docs/specs/images/prediction.png" /></p>
<p>When a localization update is received, the prediction module updates its internal status. The actual prediction is triggered when perception sends out its published perception obstacle message.</p>
</section>
<section id="localization">
<h2>Localization<a class="headerlink" href="#localization" title="永久链接至标题"></a></h2>
<p>The localization module aggregates various data to locate the autonomous vehicle. There are two types of localization modes: OnTimer and Multiple SensorFusion.</p>
<p>The first localization method is RTK-based, with a timer-based callback function <code class="docutils literal notranslate"><span class="pre">OnTimer</span></code>, as shown below.</p>
<p><img alt="img" src="https://github.com/ApolloAuto/apollo/blob/master/docs/specs/images/localization.png" /></p>
<p>The other localization method is the Multiple Sensor Fusion (MSF) method, where a bunch of event-triggered callback functions are registered, as shown  below.</p>
<p><img alt="img" src="https://github.com/ApolloAuto/apollo/blob/master/docs/specs/images/localization_2.png" /></p>
</section>
<section id="routing">
<h2>Routing<a class="headerlink" href="#routing" title="永久链接至标题"></a></h2>
<p>The routing module needs to know the routing start point and routing end point, to compute the passage lanes and roads. Usually the routing start point is the autonomous vehicle location. The important data interface is an event triggered function called <code class="docutils literal notranslate"><span class="pre">OnRoutingRequest</span></code>, in which <code class="docutils literal notranslate"><span class="pre">RoutingResponse</span></code> is computed and published as shown below.</p>
<p><img alt="img" src="https://github.com/ApolloAuto/apollo/blob/master/docs/specs/images/routing.png" /></p>
</section>
<section id="planning">
<h2>Planning<a class="headerlink" href="#planning" title="永久链接至标题"></a></h2>
<p>Apollo 2.0 uses several information sources to plan a safe and collision free trajectory, so the planning module interacts with almost every other module.</p>
<p>Initially, the planning module takes the prediction output. Because the prediction output wraps the original perceived obstacle, the planning module subscribes to the traffic light detection output rather than the perception obstacles output.</p>
<p>Then, the planning module takes the routing output. Under certain scenarios, the planning module might also trigger a new routing computation by sending a routing request if the current route cannot be faithfully followed.</p>
<p>Finally, the planning module needs to know the location (Localization: where I am) as well as the current autonomous vehicle information (Chassis: what is my status).  The planning module is also triggered by a fixed frequency, and the main data interface is the <code class="docutils literal notranslate"><span class="pre">OnTimer</span></code> callback function that invokes the <code class="docutils literal notranslate"><span class="pre">RunOnce</span></code> function.</p>
<p><img alt="img" src="https://github.com/ApolloAuto/apollo/blob/master/docs/specs/images/planning_1.png" /></p>
<p>The data dependencies such as chassis, localization, traffic light, and prediction are managed through the <code class="docutils literal notranslate"><span class="pre">AdapterManager</span></code> class. The core software modules are similarly managed.  For example, localization is managed through <code class="docutils literal notranslate"><span class="pre">AdapterManager::GetLocalization()</span></code> as shown below.<img alt="img" src="https://github.com/ApolloAuto/apollo/blob/master/docs/specs/images/planning_2.png" /></p>
</section>
<section id="control">
<h2>Control<a class="headerlink" href="#control" title="永久链接至标题"></a></h2>
<p>As described in the planning module, control takes the planned trajectory as input, and generates the control command to pass to CanBus.  It has three main data interfaces: OnPad, OnMonitor, and OnTimer.</p>
<p><img alt="img" src="https://github.com/ApolloAuto/apollo/blob/master/docs/specs/images/control_1.png" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">OnPad</span></code> and <code class="docutils literal notranslate"><span class="pre">OnMonitor</span></code> are routine interactions with the PAD-based human interface and simulations. The main data interface is the <code class="docutils literal notranslate"><span class="pre">OnTimer</span></code> interface, which periodically produces the actual control commands as shown below.</p>
<p><img alt="img" src="https://github.com/ApolloAuto/apollo/blob/master/docs/specs/images/control_2.png" /></p>
</section>
<section id="canbus">
<h2>CanBus<a class="headerlink" href="#canbus" title="永久链接至标题"></a></h2>
<p>The CanBus has two data interfaces as shown below.</p>
<p><img alt="img" src="https://github.com/ApolloAuto/apollo/blob/master/docs/specs/images/canbus_1.png" /></p>
<p>The first data interface is a timer-based publisher with the callback function <code class="docutils literal notranslate"><span class="pre">OnTimer</span></code>. This data interface periodically publishes the chassis information as well as chassis details, if enabled.</p>
<p><img alt="img" src="https://github.com/ApolloAuto/apollo/blob/master/docs/specs/images/canbus_2.png" /></p>
<p>The second data interface is an event-based publisher with a callback function <code class="docutils literal notranslate"><span class="pre">OnControlCommand</span></code>, which is triggered when the CanBus module receives control commands.</p>
</section>
<section id="hmi">
<h2>HMI<a class="headerlink" href="#hmi" title="永久链接至标题"></a></h2>
<p>Human Machine Interface or DreamView in Apollo is a web application that:
-	visualizes the current output of relevant autonomous driving modules, e.g. planning trajectory, car localization, chassis status, etc.
-	provides human-machine interface for user to view hardware status, turn on/off of modules, and start the autonomous driving car.
-	provides debugging tools, such as PnC Monitor to efficiently track module issues.</p>
</section>
<section id="monitor">
<h2>Monitor<a class="headerlink" href="#monitor" title="永久链接至标题"></a></h2>
<p>The surveillance system of all the modules in the vehicle including hardware. Monitor receives Data from different modules and passes them on to HMI for the driver to view and ensure that all the modules are working without any issue. In the event of a module or hardware failure, monitor sends an alert to Guardian (new Action Center Module) which then decides on which action needs to be taken to prevent a crash.</p>
</section>
<section id="guardian">
<h2>Guardian<a class="headerlink" href="#guardian" title="永久链接至标题"></a></h2>
<p>This new module is basically an action center that takes a decision based on the data that is sent by Monitor. There are 2 main functions of Guardian:</p>
<ul class="simple">
<li><p>All modules working fine - Guardian allows the flow of control to work normally. Control signals are sent to CANBus as if Guardian were not present.</p></li>
<li><p>Module crash is detected by Monitor - if there is a failure detected by Monitor, Guardian will prevent Control signals from reaching CANBus and bring the car to a stop. There are 3 ways in which Guardian decides how to stop the car, and to do so, Guardian turns to the final Gatekeeper, Ultrasonic sensors,</p>
<ul>
<li><p>If the Ultrasonic sensor is running fine without detecting an obstacle, Guardian will bring the car to a slow stop</p></li>
<li><p>If the sensor is not responding, Guardian applies a hard brake to bring the car to an immediate stop.</p></li>
<li><p>This is a special case, If the HMI informs the driver of an impending crash and the driver does not intervene for 10 seconds, Guardian applies a hard brake to bring the car to an immediate stop.</p></li>
</ul>
</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Note</span><span class="p">:</span> 
<span class="mf">1.</span> <span class="n">In</span> <span class="n">either</span> <span class="n">case</span> <span class="n">above</span><span class="p">,</span> <span class="n">Guardian</span> <span class="n">will</span> <span class="n">always</span> <span class="n">stop</span> <span class="n">the</span> <span class="n">car</span> <span class="n">should</span> <span class="n">Monitor</span> <span class="n">detect</span> <span class="n">a</span> <span class="n">failure</span> <span class="ow">in</span> <span class="nb">any</span> <span class="n">module</span> <span class="ow">or</span> <span class="n">hardware</span><span class="o">.</span>
<span class="mf">2.</span> <span class="n">Monitor</span> <span class="ow">and</span> <span class="n">Guardian</span> <span class="n">are</span> <span class="n">decoupled</span> <span class="n">to</span> <span class="n">ensure</span> <span class="n">that</span> <span class="n">there</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">a</span> <span class="n">single</span> <span class="n">point</span> <span class="n">of</span> <span class="n">failure</span> <span class="ow">and</span> <span class="n">also</span> <span class="n">that</span> <span class="k">with</span> <span class="n">a</span> <span class="n">module</span> <span class="n">approach</span><span class="p">,</span> <span class="n">the</span> <span class="n">action</span> <span class="n">center</span> <span class="n">can</span> <span class="n">be</span> <span class="n">modified</span> <span class="n">to</span> <span class="n">include</span> <span class="n">additional</span> <span class="n">actions</span> <span class="n">without</span> <span class="n">affecting</span> <span class="n">the</span> <span class="n">functioning</span> <span class="n">of</span> <span class="n">the</span> <span class="n">surveillance</span> <span class="n">system</span> <span class="k">as</span> <span class="n">Monitor</span> <span class="n">also</span> <span class="n">communicates</span> <span class="k">with</span> <span class="n">HMI</span><span class="o">.</span>

</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Apollo_2.0_Software_Architecture.html" class="btn btn-neutral float-left" title="Apollo 2.0 Software Architecture" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="Apollo_3.0_Software_Architecture_cn.html" class="btn btn-neutral float-right" title="Apollo 3.0 软件架构" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2021, xinetzone.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>